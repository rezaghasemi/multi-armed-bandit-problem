# Multi-Armed Bandit Problem
In probability theory, the multi-armed bandit problem (sometimes called the K- or N-armed bandit problem) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.

These algorithms are provided as the solution for this problem in this repository.

- Epsilon Greedy Method
- Decaying Epsilon Greedy Method
- Optimistic Initial Values Method
- Upper Confidence Bound (UCB1)
- Bayesian Thompson Sampling

## How to run
- `git clone https://github.com/amanraj209/multi-armed-bandit-problem.git`.
- Run `IPython Notebook` or `Python` file.